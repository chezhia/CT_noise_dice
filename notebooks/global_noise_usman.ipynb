{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Force PyQt to use its own plugins instead of the ones from OpenCV\n",
    "os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = '/media/nvme/Python/PediatricCTDataset/PEdCT/lib/python3.11/site-packages/PyQt5/Qt5/plugins'\n",
    "# Disable opencv's builtin Qt\n",
    "os.environ['OPENCV_VIDEOIO_PRIORITY_MSMF'] = '0'\n",
    "import sys\n",
    "sys.path.append('.')  # Add current directory to Python path\n",
    "import math\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from pydicom.errors import InvalidDicomError\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "from ct_viewer import CTViewer\n",
    "from ct_viewer import view_ct_volume as imtool3d\n",
    "\n",
    "from scipy import ndimage\n",
    "from rt_utils import RTStructBuilder  # Ensure rt_utils is installed.\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import glob\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "from openpyxl import Workbook\n",
    "from pydicom.errors import InvalidDicomError\n",
    "# Add to beginning of script with other imports\n",
    "VALIDATE_SUBSET = False  # Global flag for validation\n",
    "VALIDATION_INTERVAL = 50  # Validate every Nth case\n",
    "\n",
    "# Add at beginning of script with other global variables\n",
    "COMPUTE_CONFIG = {\n",
    "    'GNI': False,      # Set to False to skip GNI computation\n",
    "    'TIAN': True,      # Set to True to compute Tian noise\n",
    "    'WED': False,      # Set to False to skip WED computation\n",
    "    'VALIDATE_SUBSET': False,  # Set to True for validation\n",
    "    'VALIDATION_INTERVAL': 500  # Validate every Nth case\n",
    "}\n",
    "\n",
    "\n",
    "# def read_ct_volume(ct_dir):\n",
    "#     \"\"\"\n",
    "#     Read CT volume maintaining original DICOM order throughout processing\n",
    "#     \"\"\"\n",
    "#     # Get list of DICOM files\n",
    "#     dicom_files = glob.glob(os.path.join(ct_dir, '*.dcm'))\n",
    "    \n",
    "#     # First pass: collect instance numbers and locations\n",
    "#     file_info = []\n",
    "#     for file in dicom_files:\n",
    "#         ds = pydicom.dcmread(file)\n",
    "#         file_info.append({\n",
    "#             'file': file,\n",
    "#             'instance_number': int(ds.InstanceNumber),\n",
    "#             'location': float(ds.SliceLocation)\n",
    "#         })\n",
    "    \n",
    "#     # Sort files once by instance number\n",
    "#     file_info.sort(key=lambda x: x['instance_number'])\n",
    "#     sorted_files = [info['file'] for info in file_info]\n",
    "    \n",
    "#     # Read first file for metadata\n",
    "#     first_slice = pydicom.dcmread(sorted_files[0])\n",
    "#     shape = (len(sorted_files), first_slice.Rows, first_slice.Columns)\n",
    "#     slope = float(first_slice.RescaleSlope)\n",
    "#     intercept = float(first_slice.RescaleIntercept)\n",
    "#     pixel_spacing = first_slice.PixelSpacing\n",
    "    \n",
    "#     # Initialize arrays\n",
    "#     ct_data = np.zeros(shape, dtype=np.float32)\n",
    "#     tube_current = np.zeros(len(sorted_files))\n",
    "#     slice_locations = np.zeros(len(sorted_files))\n",
    "    \n",
    "#     # Read data in sorted order\n",
    "#     for idx, file in enumerate(sorted_files):\n",
    "#         ds = pydicom.dcmread(file)\n",
    "#         ct_data[idx] = ds.pixel_array\n",
    "#         tube_current[idx] = float(ds.XRayTubeCurrent)\n",
    "#         slice_locations[idx] = float(ds.SliceLocation)\n",
    "    \n",
    "#     # Convert to HU\n",
    "#     ct_data = ct_data * slope + intercept\n",
    "    \n",
    "#     return ct_data, pixel_spacing, tube_current, slice_locations\n",
    "\n",
    "# def create_body_mask(contour):\n",
    "#     mask = np.zeros_like(contour)\n",
    "#     for i in range(contour.shape[0]):\n",
    "#         for x in range(contour.shape[2]):\n",
    "#             contour_col = contour[i, :, x]\n",
    "#             contour_points = np.where(contour_col > 0)[0]\n",
    "#             if len(contour_points) > 0:\n",
    "#                 min_y = np.min(contour_points)\n",
    "#                 max_y = np.max(contour_points)\n",
    "#                 mask[i, min_y:max_y, x] = 1\n",
    "#     return mask\n",
    "\n",
    "def remove_table(ct_data, contour):\n",
    "    cleaned = ct_data.copy()\n",
    "    for i in range(ct_data.shape[0]):\n",
    "        for x in range(ct_data.shape[2]):\n",
    "            # Find the contour points in this column\n",
    "            contour_col = contour[i, :, x]\n",
    "            contour_points = np.where(contour_col > 0)[0]\n",
    "            if len(contour_points) > 0:\n",
    "                min_y = np.min(contour_points)\n",
    "                max_y = np.max(contour_points)\n",
    "                # Set everything above and below contour to -1000 HU\n",
    "                cleaned[i, :min_y, x] = -1000  # Above body\n",
    "                cleaned[i, max_y:, x] = -1000  # Below body\n",
    "            else:\n",
    "                # If no contour in this column, set all to air\n",
    "                cleaned[i, :, x] = -1000\n",
    "    return cleaned\n",
    "\n",
    "def compute_wed(ct_data, mask, pixel_width, pixel_height):\n",
    "    wed = np.zeros(ct_data.shape[0])\n",
    "    A_pixel = pixel_width/10 * pixel_height/10  # cm²\n",
    "        \n",
    "    for i in range(ct_data.shape[0]):\n",
    "        roi_mask = mask[i].astype(bool)\n",
    "        \n",
    "        # Only include pixels within the mask\n",
    "        roi_pixels = ct_data[i][roi_mask]\n",
    "        \n",
    "        # Calculate mean CT number in ROI\n",
    "        mean_CT = np.mean(roi_pixels)\n",
    "        \n",
    "        # Calculate total ROI area, A_ROI = N_pixels (num of pixels) * A_pixel (mm²)\n",
    "        A_ROI = np.sum(roi_mask) * A_pixel\n",
    "        \n",
    "        # Calculate water equivalent area using equation from AAPM Report 220\n",
    "        A_w = ((1/1000) * mean_CT * A_ROI) + A_ROI\n",
    "        \n",
    "        # Convert area to diameter\n",
    "        wed[i] = 2 * np.sqrt(A_w / np.pi)\n",
    "        \n",
    "    return wed\n",
    "def calculate_volume_gni(ct_volume):\n",
    "    # Initialize array to store noise values for each slice\n",
    "    volume_noise = []\n",
    "    \n",
    "    # Process each slice in the volume\n",
    "    for slice_idx in range(ct_volume.shape[0]):\n",
    "        ct_slice = ct_volume[slice_idx]\n",
    "        \n",
    "        # Calculate noise map for current slice\n",
    "        noise_map = np.zeros_like(ct_slice, dtype=float)\n",
    "        kernel_size = 10\n",
    "        for i in range(ct_slice.shape[0] - kernel_size):\n",
    "            for j in range(ct_slice.shape[1] - kernel_size):\n",
    "                window = ct_slice[i:i+kernel_size, j:j+kernel_size]\n",
    "                noise_map[i,j] = np.std(window)\n",
    "        \n",
    "        # Calculate gradient to exclude anatomical borders\n",
    "        sobelx = cv2.Sobel(ct_slice, cv2.CV_64F, 1, 0)\n",
    "        sobely = cv2.Sobel(ct_slice, cv2.CV_64F, 0, 1)\n",
    "        gradient_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "        \n",
    "        # Exclude high gradient areas\n",
    "        gradient_threshold = 10\n",
    "        valid_pixels = gradient_mag < gradient_threshold\n",
    "        slice_noise = noise_map[valid_pixels]\n",
    "        \n",
    "        # Store histogram mode for this slice\n",
    "        if len(slice_noise) > 0:\n",
    "            volume_noise.append(np.argmax(np.histogram(slice_noise, bins=100)[0]))\n",
    "    \n",
    "    # Return mean GNI across all slices\n",
    "    return np.mean(volume_noise)\n",
    "def plot_parameter_vs_location(slice_locations, parameter_values, \n",
    "                             parameter_name, ax=None, color='blue'):\n",
    "    \"\"\"\n",
    "    Plot any parameter against slice location\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "    ax.plot(slice_locations, parameter_values, '-o', color=color, markersize=4)\n",
    "    ax.set_xlabel('Slice Location (mm)')\n",
    "    ax.set_ylabel(parameter_name)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def create_analysis_plots(slice_locations, wed, tube_current, gni=None):\n",
    "    \"\"\"\n",
    "    Create comprehensive analysis plots\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3 if gni is not None else 2, 1, \n",
    "                            figsize=(12, 12), sharex=True)\n",
    "    fig.suptitle('CT Scan Analysis')\n",
    "    \n",
    "    # Plot WED\n",
    "    plot_parameter_vs_location(slice_locations, wed, \n",
    "                             'Water Equivalent Diameter (cm)', \n",
    "                             ax=axes[0], color='blue')\n",
    "    \n",
    "    # Plot tube current\n",
    "    plot_parameter_vs_location(slice_locations, tube_current, \n",
    "                             'Tube Current (mA)', \n",
    "                             ax=axes[1], color='red')\n",
    "    \n",
    "    \n",
    "    #define second y-axis that shares x-axis with current plot\n",
    "\n",
    "    # Plot GNI if available\n",
    "    if gni is not None:\n",
    "        plot_parameter_vs_location(slice_locations, gni, \n",
    "                                 'Global Noise Index (HU)', \n",
    "                                 ax=axes[2], color='green')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "def plot_wed_tubecurrent_overlay(slice_locations, wed, tube_current):\n",
    "    \"\"\"\n",
    "    Create an overlay plot of WED and tube current vs slice location with dual axes\n",
    "    \"\"\"\n",
    "    # Set colors\n",
    "    col1 = 'steelblue'\n",
    "    col2 = 'red'\n",
    "    \n",
    "    # Create figure and primary axis\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot tube current on primary axis\n",
    "    ax1.plot(slice_locations, tube_current, color=col1, label='Tube Current')\n",
    "    ax1.set_xlabel('Slice Location (mm)', fontsize=14)\n",
    "    ax1.set_ylabel('X-Ray Tube Current (mA)', color=col1, fontsize=16)\n",
    "    ax1.tick_params(axis='y', labelcolor=col1)\n",
    "    \n",
    "    # Create secondary axis and plot WED\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(slice_locations, wed, color=col2, label='WED')\n",
    "    ax2.set_ylabel('Water Equivalent Diameter (cm)', color=col2, fontsize=16)\n",
    "    ax2.tick_params(axis='y', labelcolor=col2)\n",
    "    \n",
    "    # Add legend\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "    \n",
    "    # Add grid (only for primary axis)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.title('Tube Current and Water Equivalent Diameter vs. Slice Location', \n",
    "              fontsize=14, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, (ax1, ax2)\n",
    "\n",
    "# def compute_gni(ct_data, kernel_size_mm=6, hu_bins=0.1, pixel_spacing=None):\n",
    "#     \"\"\"\n",
    "#     Compute Global Noise Index for each slice following Christianson's method\n",
    "#     \"\"\"\n",
    "#     # Convert kernel size from mm to pixels\n",
    "#     kernel_size_px = int(round(kernel_size_mm / pixel_spacing[0]))\n",
    "#     if kernel_size_px % 2 == 0:\n",
    "#         kernel_size_px += 1\n",
    "        \n",
    "#     gni_values = np.zeros(ct_data.shape[0])\n",
    "    \n",
    "#     for slice_idx in range(ct_data.shape[0]):\n",
    "#         ct_slice = ct_data[slice_idx]\n",
    "        \n",
    "#         # Segment soft tissue (0-100 HU as per paper)\n",
    "#         tissue_mask = (ct_slice >= 0) & (ct_slice <= 100)\n",
    "        \n",
    "#         # Generate noise map\n",
    "#         noise_map = ndimage.generic_filter(\n",
    "#             ct_slice,\n",
    "#             np.std,\n",
    "#             size=kernel_size_px,\n",
    "#             mode='constant',\n",
    "#             cval=np.nan\n",
    "#         )\n",
    "        \n",
    "#         # Extract noise values from soft tissue regions\n",
    "#         tissue_noise = noise_map[tissue_mask]\n",
    "#         tissue_noise = tissue_noise[~np.isnan(tissue_noise)]\n",
    "        \n",
    "#         if len(tissue_noise) > 0:\n",
    "#             # Create histogram and find mode\n",
    "#             hist, bins = np.histogram(\n",
    "#                 tissue_noise,\n",
    "#                 bins=np.arange(0, np.nanmax(tissue_noise) + hu_bins, hu_bins)\n",
    "#             )\n",
    "#             gni_values[slice_idx] = bins[np.argmax(hist)]\n",
    "#         else:\n",
    "#             gni_values[slice_idx] = np.nan\n",
    "            \n",
    "#     return gni_values```python\n",
    "\n",
    "def compute_gni_optimized(ct_data, kernel_size_mm=6, hu_bins=0.1, pixel_spacing=None, body_mask=None, debug_slice=None):\n",
    "    \"\"\"\n",
    "    Compute Global Noise Index with proper body and tissue masking\n",
    "    Args:\n",
    "        ct_data: 3D CT volume in HU\n",
    "        kernel_size_mm: kernel size in mm (default 6mm per paper)\n",
    "        hu_bins: histogram bin size in HU\n",
    "        pixel_spacing: pixel spacing in mm\n",
    "        body_mask: binary mask of body region (1 inside body, 0 outside)\n",
    "        debug_slice: slice index to show debug visualizations\n",
    "    \"\"\"\n",
    "    kernel_size_px = int(round(kernel_size_mm / pixel_spacing[0]))\n",
    "    if kernel_size_px % 2 == 0:\n",
    "        kernel_size_px += 1\n",
    "        \n",
    "    gni_values = np.zeros(ct_data.shape[0])\n",
    "    kernel = np.ones((kernel_size_px, kernel_size_px))\n",
    "    kernel_size = kernel_size_px * kernel_size_px\n",
    "    \n",
    "    for slice_idx in range(ct_data.shape[0]):\n",
    "        ct_slice = ct_data[slice_idx]\n",
    "        body_region = body_mask[slice_idx] if body_mask is not None else np.ones_like(ct_slice)\n",
    "        \n",
    "        # Step 1: Segment soft tissue ONLY within body mask\n",
    "        tissue_mask = (ct_slice >= 0) & (ct_slice <= 100) & (body_region > 0)\n",
    "        \n",
    "        if np.any(tissue_mask):\n",
    "            # Step 2: Generate noise map\n",
    "            pad_width = kernel_size_px//2\n",
    "            slice_pad = np.pad(ct_slice, pad_width, mode='edge')\n",
    "            \n",
    "            # Calculate standard deviations\n",
    "            sum_conv = ndimage.convolve(slice_pad, kernel)\n",
    "            sum_sq_conv = ndimage.convolve(slice_pad**2, kernel)\n",
    "            \n",
    "            # Remove padding\n",
    "            sum_conv = sum_conv[pad_width:-pad_width, pad_width:-pad_width]\n",
    "            sum_sq_conv = sum_sq_conv[pad_width:-pad_width, pad_width:-pad_width]\n",
    "            \n",
    "            mean = sum_conv / kernel_size\n",
    "            variance = (sum_sq_conv / kernel_size) - mean**2\n",
    "            noise_map = np.sqrt(np.maximum(variance, 0))\n",
    "            \n",
    "            # Only consider noise values within tissue mask\n",
    "            noise_values = noise_map[tissue_mask]\n",
    "            \n",
    "            if len(noise_values) > 0:\n",
    "                # Create histogram excluding zeros and outliers\n",
    "                valid_noise = noise_values[noise_values > 0]\n",
    "                if len(valid_noise) > 0:\n",
    "                    max_noise = np.percentile(valid_noise, 99)  # Exclude extreme outliers\n",
    "                    hist, bins = np.histogram(\n",
    "                        valid_noise,\n",
    "                        bins=np.arange(0, max_noise + hu_bins, hu_bins),\n",
    "                        density=False\n",
    "                    )\n",
    "                    peak_idx = np.argmax(hist)\n",
    "                    gni_values[slice_idx] = bins[peak_idx]\n",
    "                else:\n",
    "                    gni_values[slice_idx] = np.nan\n",
    "            else:\n",
    "                gni_values[slice_idx] = np.nan\n",
    "                \n",
    "            # Debug visualization\n",
    "            if debug_slice is not None and slice_idx == debug_slice:\n",
    "                fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "                \n",
    "                # Original image\n",
    "                im1 = axes[0,0].imshow(ct_slice * body_region, cmap='gray')\n",
    "                axes[0,0].set_title('Original CT Slice (Body Region Only)')\n",
    "                plt.colorbar(im1, ax=axes[0,0], label='HU')\n",
    "                \n",
    "                # Tissue mask (white = included tissue)\n",
    "                axes[0,1].imshow(tissue_mask, cmap='gray')  # Changed to gray colormap\n",
    "                axes[0,1].set_title('Soft Tissue Mask (White = Included)')\n",
    "                \n",
    "                # Noise map (only showing within tissue mask)\n",
    "                masked_noise = np.where(tissue_mask, noise_map, np.nan)\n",
    "                im3 = axes[1,0].imshow(masked_noise, cmap='viridis')\n",
    "                axes[1,0].set_title('Noise Map (Only in Soft Tissue)')\n",
    "                plt.colorbar(im3, ax=axes[1,0], label='HU')\n",
    "                \n",
    "                # Noise histogram\n",
    "                if len(valid_noise) > 0:\n",
    "                    axes[1,1].hist(valid_noise, bins='auto', density=False, alpha=0.7)\n",
    "                    axes[1,1].axvline(bins[peak_idx], color='r', linestyle='--', \n",
    "                                    label=f'Mode (GNI) = {bins[peak_idx]:.1f}')\n",
    "                    axes[1,1].set_title('Noise Histogram in Soft Tissue')\n",
    "                    axes[1,1].set_xlabel('Standard Deviation (HU)')\n",
    "                    axes[1,1].set_ylabel('Frequency')\n",
    "                    axes[1,1].legend()\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "        else:\n",
    "            gni_values[slice_idx] = np.nan\n",
    "    \n",
    "    return gni_values\n",
    "\n",
    "def plot_metrics_comparison_optimized(slice_locations, wed, tube_current, gni):\n",
    "    \"\"\"\n",
    "    Create efficient plot using precomputed arrays\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    # Plot all data at once for each axis\n",
    "    l1 = ax1.plot(slice_locations, tube_current, 'steelblue', label='Tube Current')[0]\n",
    "    ax1_twin = ax1.twinx()\n",
    "    l2 = ax1_twin.plot(slice_locations, wed, 'red', label='WED')[0]\n",
    "    \n",
    "    # Set labels and colors once\n",
    "    ax1.set_ylabel('X-Ray Tube Current (mA)', color='steelblue', fontsize=12)\n",
    "    ax1_twin.set_ylabel('WED (cm)', color='red', fontsize=12)\n",
    "    ax1.tick_params(axis='y', labelcolor='steelblue')\n",
    "    ax1_twin.tick_params(axis='y', labelcolor='red')\n",
    "    \n",
    "    # Add single legend\n",
    "    ax1.legend([l1, l2], ['Tube Current', 'WED'], loc='upper right')\n",
    "    \n",
    "    # Plot GNI\n",
    "    ax2.plot(slice_locations, gni, 'green', label='GNI')\n",
    "    ax2.set_xlabel('Slice Location (mm)', fontsize=12)\n",
    "    ax2.set_ylabel('GNI (HU)', fontsize=12)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Add grids\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('CT Metrics Comparison', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, (ax1, ax2)\n",
    "\n",
    "def validate_gni(ct_slice, gni_value):\n",
    "    \"\"\"\n",
    "    Validate GNI by comparing to manual ROI measurements in uniform regions\n",
    "    \"\"\"\n",
    "    # Place multiple ROIs in uniform soft tissue regions\n",
    "    roi_size = 10\n",
    "    roi_centers = [\n",
    "        (256, 256),  # example center coordinates\n",
    "        (256, 276),\n",
    "        (256, 236)\n",
    "    ]\n",
    "    \n",
    "    manual_noise = []\n",
    "    for center in roi_centers:\n",
    "        y, x = center\n",
    "        roi = ct_slice[y-roi_size//2:y+roi_size//2, \n",
    "                      x-roi_size//2:x+roi_size//2]\n",
    "        if np.all((roi >= 0) & (roi <= 100)):  # Check if ROI is in soft tissue\n",
    "            manual_noise.append(np.std(roi))\n",
    "    \n",
    "    mean_manual_noise = np.mean(manual_noise)\n",
    "    print(f\"GNI value: {gni_value:.2f}\")\n",
    "    print(f\"Manual ROI noise: {mean_manual_noise:.2f}\")\n",
    "    return gni_value, mean_manual_noise\n",
    "\n",
    "def compare_with_reference():\n",
    "    \"\"\"Common noise values from literature\"\"\"\n",
    "    # From Christianson paper:\n",
    "    # Abdomen CT typical noise range: 10-20 HU\n",
    "    # From AAPM guidelines:\n",
    "    # Head CT typical noise range: 3-7 HU\n",
    "    # Body CT typical noise range: 10-18 HU\n",
    "    \n",
    "    print(\"Noise distribution in our data:\")\n",
    "    print(f\"Mean GNI: {np.nanmean(gni_values):.2f}\")\n",
    "    print(f\"Range: {np.nanmin(gni_values):.2f} - {np.nanmax(gni_values):.2f}\")\n",
    "    \n",
    "def validate_noise_calculations(ct_data, pixel_spacing, tube_current, wed, gni_values):\n",
    "    \"\"\"\n",
    "    Comprehensive validation of noise calculations\n",
    "    \"\"\"\n",
    "    # 1. Physical relationship validation\n",
    "    mAs_factor = 1/np.sqrt(tube_current)\n",
    "    wed_factor = np.exp(wed/2)\n",
    "    \n",
    "    noise_mAs_corr = np.corrcoef(gni_values[~np.isnan(gni_values)], \n",
    "                                mAs_factor[~np.isnan(gni_values)])[0,1]\n",
    "    noise_wed_corr = np.corrcoef(gni_values[~np.isnan(gni_values)], \n",
    "                                wed_factor[~np.isnan(gni_values)])[0,1]\n",
    "    \n",
    "    print(\"\\nPhysical Relationship Validation:\")\n",
    "    print(f\"Noise vs 1/√(mAs) correlation: {noise_mAs_corr:.3f}\")\n",
    "    print(f\"Noise vs exp(WED/2) correlation: {noise_wed_corr:.3f}\")\n",
    "    \n",
    "    # 2. Check noise range against literature\n",
    "    print(\"\\nNoise Range Validation:\")\n",
    "    compare_with_reference()\n",
    "    \n",
    "    # 3. Manual ROI validation\n",
    "    print(\"\\nManual ROI Validation:\")\n",
    "    slice_idx = len(ct_data)//2  # middle slice\n",
    "    gni, manual = validate_gni(ct_data[slice_idx], gni_values[slice_idx])\n",
    "    print(f\"Percent difference: {100*abs(gni-manual)/manual:.1f}%\")\n",
    "\n",
    "    # 4. Plot noise distributions\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.hist(gni_values[~np.isnan(gni_values)], bins=50)\n",
    "    plt.xlabel('Noise (HU)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of GNI Values')\n",
    "    plt.show()\n",
    "    \n",
    "def read_ct_volume(ct_dir):\n",
    "    \"\"\"\n",
    "    Read CT volume maintaining original DICOM order throughout processing.\n",
    "    \"\"\"\n",
    "    dicom_files = glob.glob(os.path.join(ct_dir, '*.dcm'))\n",
    "    \n",
    "    # Collect instance numbers and locations\n",
    "    file_info = []\n",
    "    for file in dicom_files:\n",
    "        ds = pydicom.dcmread(file)\n",
    "        file_info.append({\n",
    "            'file': file,\n",
    "            'instance_number': int(ds.InstanceNumber),\n",
    "            'location': float(ds.SliceLocation)\n",
    "        })\n",
    "    \n",
    "    # Sort files once by instance number\n",
    "    file_info.sort(key=lambda x: x['instance_number'])\n",
    "    sorted_files = [info['file'] for info in file_info]\n",
    "    \n",
    "    # Read first file for metadata\n",
    "    first_slice = pydicom.dcmread(sorted_files[0])\n",
    "    shape = (len(sorted_files), first_slice.Rows, first_slice.Columns)\n",
    "    slope = float(first_slice.RescaleSlope)\n",
    "    intercept = float(first_slice.RescaleIntercept)\n",
    "    pixel_spacing = first_slice.PixelSpacing\n",
    "    \n",
    "    # Initialize arrays\n",
    "    ct_data = np.zeros(shape, dtype=np.float32)\n",
    "    tube_current = np.zeros(len(sorted_files))\n",
    "    slice_locations = np.zeros(len(sorted_files))\n",
    "    \n",
    "    # Read data in sorted order\n",
    "    for idx, file in enumerate(sorted_files):\n",
    "        ds = pydicom.dcmread(file)\n",
    "        ct_data[idx] = ds.pixel_array\n",
    "        tube_current[idx] = float(ds.XRayTubeCurrent)\n",
    "        slice_locations[idx] = float(ds.SliceLocation)\n",
    "    \n",
    "    # Convert to HU\n",
    "    ct_data = ct_data * slope + intercept\n",
    "    \n",
    "    return ct_data, pixel_spacing, tube_current, slice_locations\n",
    "\n",
    "\n",
    "# def get_dicom_files(case_root: str) -> Tuple[List[str], Optional[str]]:\n",
    "#     \"\"\"\n",
    "#     Recursively searches the case_root for DICOM files.\n",
    "    \n",
    "#     Returns:\n",
    "#       - ct_files: List of file paths for CT slices (Modality == \"CT\")\n",
    "#       - rtstruct_file: File path for the RTSTRUCT (Modality == \"RTSTRUCT\"), if found.\n",
    "#     \"\"\"\n",
    "#     ct_files = []\n",
    "#     rtstruct_file = None\n",
    "#     for root, _, files in os.walk(case_root):\n",
    "#         for file in files:\n",
    "#             if not file.lower().endswith('.dcm'):\n",
    "#                 continue\n",
    "#             file_path = os.path.join(root, file)\n",
    "#             try:\n",
    "#                 ds = pydicom.dcmread(file_path, stop_before_pixels=True)\n",
    "#             except (InvalidDicomError, Exception) as e:\n",
    "#                 logging.warning(f\"Error reading file {file_path}: {e}\")\n",
    "#                 continue\n",
    "#             modality = ds.get(\"Modality\", \"\").upper()\n",
    "#             if modality == \"CT\":\n",
    "#                 ct_files.append(file_path)\n",
    "#             elif modality == \"RTSTRUCT\":\n",
    "#                 rtstruct_file = file_path\n",
    "#     if not ct_files:\n",
    "#         raise ValueError(f\"No CT files found in {case_root}\")\n",
    "#     if rtstruct_file is None:\n",
    "#         logging.warning(f\"No RTSTRUCT file found in {case_root}. Using fallback threshold segmentation for body mask.\")\n",
    "#     return ct_files, rtstruct_file\n",
    "\n",
    "# =============================================================================\n",
    "# Main Processing Function\n",
    "# =============================================================================\n",
    "\n",
    "def parse_rtstruct(rtstruct_file: str, ct_dir: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Parses the RTSTRUCT file using the rt_utils package.\n",
    "    \n",
    "    Returns:\n",
    "      A dictionary mapping ROI names to 3D binary masks (shape: [num_slices, height, width]).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from rt_utils import RTStructBuilder  # Ensure rt_utils is installed.\n",
    "        rtstruct = RTStructBuilder.create_from(dicom_series_path=ct_dir, rt_struct_path=rtstruct_file)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading RTSTRUCT file: {e}\")\n",
    "    \n",
    "    roi_names = rtstruct.get_roi_names()\n",
    "    logging.info(f\"Available ROI names: {roi_names}\")\n",
    "    masks = {}\n",
    "    for roi in roi_names:\n",
    "        try:\n",
    "            mask = rtstruct.get_roi_mask_by_name(roi).astype(bool)\n",
    "            # Only attempt transposition if the expected attribute is present.\n",
    "            if mask.ndim == 3:\n",
    "                if hasattr(rtstruct, 'dicom_series'):\n",
    "                    if mask.shape[0] != rtstruct.dicom_series.shape[0]:\n",
    "                        mask = np.transpose(mask, (2, 0, 1))\n",
    "                else:\n",
    "                    # If dicom_series attribute is not present, skip transposition.\n",
    "                    logging.warning(f\"Attribute 'dicom_series' not found in RTSTRUCT for ROI '{roi}'.\")\n",
    "            masks[roi] = mask\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error processing ROI {roi}: {e}\")\n",
    "            continue\n",
    "    return masks\n",
    "# =============================================================================\n",
    "# Helper Functions\n",
    "# =============================================================================\n",
    "\n",
    "def read_ct_volume(ct_dir):\n",
    "    \"\"\"\n",
    "    Read CT volume maintaining original DICOM order throughout processing.\n",
    "    \"\"\"\n",
    "    dicom_files = glob.glob(os.path.join(ct_dir, '*.dcm'))\n",
    "    \n",
    "    # First pass: collect instance numbers and locations\n",
    "    file_info = []\n",
    "    for file in dicom_files:\n",
    "        ds = pydicom.dcmread(file)\n",
    "        file_info.append({\n",
    "            'file': file,\n",
    "            'instance_number': int(ds.InstanceNumber),\n",
    "            'location': float(ds.SliceLocation)\n",
    "        })\n",
    "    \n",
    "    # Sort files once by instance number\n",
    "    file_info.sort(key=lambda x: x['instance_number'])\n",
    "    sorted_files = [info['file'] for info in file_info]\n",
    "    \n",
    "    # Read first file for metadata\n",
    "    first_slice = pydicom.dcmread(sorted_files[0])\n",
    "    shape = (len(sorted_files), first_slice.Rows, first_slice.Columns)\n",
    "    slope = float(first_slice.RescaleSlope)\n",
    "    intercept = float(first_slice.RescaleIntercept)\n",
    "    pixel_spacing = first_slice.PixelSpacing\n",
    "    \n",
    "    # Initialize arrays\n",
    "    ct_data = np.zeros(shape, dtype=np.float32)\n",
    "    tube_current = np.zeros(len(sorted_files))\n",
    "    slice_locations = np.zeros(len(sorted_files))\n",
    "    \n",
    "    # Read data in sorted order\n",
    "    for idx, file in enumerate(sorted_files):\n",
    "        ds = pydicom.dcmread(file)\n",
    "        ct_data[idx] = ds.pixel_array\n",
    "        tube_current[idx] = float(ds.XRayTubeCurrent)\n",
    "        slice_locations[idx] = float(ds.SliceLocation)\n",
    "    \n",
    "    # Convert to HU\n",
    "    ct_data = ct_data * slope + intercept\n",
    "    \n",
    "    return ct_data, pixel_spacing, tube_current, slice_locations\n",
    "\n",
    "\n",
    "def get_dicom_files(case_root: str) -> Tuple[List[str], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Recursively searches the case_root for DICOM files.\n",
    "    \n",
    "    Returns:\n",
    "      - ct_files: List of file paths for CT slices (Modality == \"CT\")\n",
    "      - rtstruct_file: File path for the RTSTRUCT (Modality == \"RTSTRUCT\"), if found.\n",
    "    \"\"\"\n",
    "    ct_files = []\n",
    "    rtstruct_file = None\n",
    "    for root, _, files in os.walk(case_root):\n",
    "        for file in files:\n",
    "            if not file.lower().endswith('.dcm'):\n",
    "                continue\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                ds = pydicom.dcmread(file_path, stop_before_pixels=True)\n",
    "            except (InvalidDicomError, Exception) as e:\n",
    "                logging.warning(f\"Error reading file {file_path}: {e}\")\n",
    "                continue\n",
    "            modality = ds.get(\"Modality\", \"\").upper()\n",
    "            if modality == \"CT\":\n",
    "                ct_files.append(file_path)\n",
    "            elif modality == \"RTSTRUCT\":\n",
    "                rtstruct_file = file_path\n",
    "    if not ct_files:\n",
    "        raise ValueError(f\"No CT files found in {case_root}\")\n",
    "    if rtstruct_file is None:\n",
    "        logging.warning(f\"No RTSTRUCT file found in {case_root}. Using fallback threshold segmentation for body mask.\")\n",
    "    return ct_files, rtstruct_file\n",
    "\n",
    "\n",
    "def create_body_mask(contour):\n",
    "    \"\"\"\n",
    "    Generate a body mask from RTSTRUCT contours.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(contour)\n",
    "    for i in range(contour.shape[0]):\n",
    "        for x in range(contour.shape[2]):\n",
    "            contour_col = contour[i, :, x]\n",
    "            contour_points = np.where(contour_col > 0)[0]\n",
    "            if len(contour_points) > 0:\n",
    "                min_y = np.min(contour_points)\n",
    "                max_y = np.max(contour_points)\n",
    "                mask[i, min_y:max_y, x] = 1\n",
    "    return mask\n",
    "\n",
    "def compute_tian_noise2(ct_data: np.ndarray, body_mask: np.ndarray = None, \n",
    "                      roi_size: int = 30, edge_threshold: float = 100) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute noise using Tian's subtraction method with proper tissue segmentation.\n",
    "    \n",
    "    Implementation follows: \n",
    "    Tian X, Samei E. Accurate assessment and prediction of noise in clinical CT images. \n",
    "    Med Phys. 2016;43(1):475-482.\n",
    "    \n",
    "    Method steps:\n",
    "    1. Sequential slice subtraction to remove anatomical correlations\n",
    "    2. Edge detection to identify remaining structural transitions\n",
    "    3. ROI-based noise analysis in homogeneous regions\n",
    "    \n",
    "    Args:\n",
    "        ct_data: 3D CT volume in HU [slices, rows, cols]\n",
    "        body_mask: Binary mask of body region (1 inside, 0 outside)\n",
    "        roi_size: Size of ROI patches for noise analysis (default 30 per paper)\n",
    "        edge_threshold: Gradient magnitude threshold for edge detection\n",
    "        \n",
    "    Returns:\n",
    "        noise_values: Array of noise measurements per slice\n",
    "        \n",
    "    Note:\n",
    "        - Body mask is used to constrain analysis to patient tissue\n",
    "        - Edge detection threshold based on gradient magnitude in HU\n",
    "        - Noise computed as SD/√2 due to subtraction of independent noise\n",
    "    \"\"\"\n",
    "    num_slices = ct_data.shape[0]\n",
    "    noise_values = np.zeros(num_slices)\n",
    "    \n",
    "    # Process each slice except last one\n",
    "    for i in range(num_slices - 1):\n",
    "        try:\n",
    "            # 1. Sequential slice subtraction\n",
    "            diff_image = ct_data[i] - ct_data[i + 1]\n",
    "            \n",
    "            # Apply body mask to difference image\n",
    "            if body_mask is not None:\n",
    "                # Use intersection of masks from both slices\n",
    "                combined_mask = body_mask[i] & body_mask[i + 1]\n",
    "                diff_image = np.where(combined_mask, diff_image, np.nan)\n",
    "            \n",
    "            # 2. Edge detection on difference image\n",
    "            sobelx = cv2.Sobel(diff_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "            sobely = cv2.Sobel(diff_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "            gradient_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "            \n",
    "            # Create edge mask\n",
    "            edge_mask = gradient_mag < edge_threshold\n",
    "            \n",
    "            # 3. ROI-based noise analysis\n",
    "            valid_noise_values = []\n",
    "            \n",
    "            # Step through image with 50% overlap between ROIs\n",
    "            step_size = roi_size // 2\n",
    "            for y in range(0, diff_image.shape[0] - roi_size, step_size):\n",
    "                for x in range(0, diff_image.shape[1] - roi_size, step_size):\n",
    "                    # Extract ROI\n",
    "                    roi = diff_image[y:y + roi_size, x:x + roi_size]\n",
    "                    roi_edge_mask = edge_mask[y:y + roi_size, x:x + roi_size]\n",
    "                    \n",
    "                    if body_mask is not None:\n",
    "                        roi_body_mask = combined_mask[y:y + roi_size, x:x + roi_size]\n",
    "                        # Skip if ROI not fully within body\n",
    "                        if not np.all(roi_body_mask):\n",
    "                            continue\n",
    "                    \n",
    "                    # Skip if ROI contains edges\n",
    "                    if not np.all(roi_edge_mask):\n",
    "                        continue\n",
    "                        \n",
    "                    # Skip if ROI contains invalid values\n",
    "                    if np.any(np.isnan(roi)):\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate noise\n",
    "                    noise = np.std(roi) / np.sqrt(2)  # Divide by √2 due to subtraction\n",
    "                    valid_noise_values.append(noise)\n",
    "            \n",
    "            if valid_noise_values:\n",
    "                # Use median for robustness to outliers\n",
    "                noise_values[i] = np.median(valid_noise_values)\n",
    "            else:\n",
    "                noise_values[i] = np.nan\n",
    "                logging.info(f\"No valid noise measurements found for slice {i}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing slice {i}: {str(e)}\")\n",
    "            noise_values[i] = np.nan\n",
    "            \n",
    "    # Handle last slice using last valid measurement\n",
    "    valid_indices = np.where(~np.isnan(noise_values))[0]\n",
    "    if len(valid_indices) > 0:\n",
    "        noise_values[-1] = noise_values[valid_indices[-1]]\n",
    "    else:\n",
    "        noise_values[-1] = np.nan\n",
    "    \n",
    "    return noise_values\n",
    "\n",
    "def validate_noise_methods2(ct_data: np.ndarray, gni_values: np.ndarray, \n",
    "                         tian_values: np.ndarray, slice_idx: Optional[int] = None) -> None:\n",
    "    \"\"\"\n",
    "    Compare and validate both noise measurement methods.\n",
    "    \n",
    "    Args:\n",
    "        ct_data: Original CT volume\n",
    "        gni_values: GNI measurements\n",
    "        tian_values: Tian noise measurements\n",
    "        slice_idx: Optional specific slice to analyze\n",
    "    \"\"\"\n",
    "    if slice_idx is None:\n",
    "        slice_idx = ct_data.shape[0] // 2  # Use middle slice\n",
    "        \n",
    "    # Compare measurements\n",
    "    print(f\"\\nNoise Comparison for Slice {slice_idx}:\")\n",
    "    print(f\"GNI Value: {gni_values[slice_idx]:.2f} HU\")\n",
    "    print(f\"Tian Value: {tian_values[slice_idx]:.2f} HU\")\n",
    "    \n",
    "    # Calculate % difference\n",
    "    if not np.isnan(gni_values[slice_idx]) and not np.isnan(tian_values[slice_idx]):\n",
    "        pct_diff = 100 * abs(gni_values[slice_idx] - tian_values[slice_idx]) / gni_values[slice_idx]\n",
    "        print(f\"Percent Difference: {pct_diff:.1f}%\")\n",
    "    \n",
    "    # Literature comparison\n",
    "    print(\"\\nTypical Ranges from Literature:\")\n",
    "    print(\"Head CT: 3-7 HU\")\n",
    "    print(\"Body CT: 10-18 HU\")\n",
    "    \n",
    "    # Optional: Generate validation plots\n",
    "    if COMPUTE_CONFIG['VALIDATE_SUBSET']:\n",
    "        validate_tian_noise(ct_data, tian_values, slice_idx)\n",
    "\n",
    "def get_optimal_bin_width(data):\n",
    "    \"\"\"\n",
    "    Calculate optimal bin width using Freedman-Diaconis rule.\n",
    "    Optimal bin width = 2 * IQR * n^(-1/3)\n",
    "    where IQR is interquartile range and n is number of observations\n",
    "    \"\"\"\n",
    "    q75, q25 = np.percentile(data, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    n = len(data)\n",
    "    width = 2 * iqr * (n ** (-1/3))\n",
    "    return max(width, 0.1)  # Minimum 0.1 HU bin width for precision\n",
    "\n",
    "def plot_noise_profile(ct_data: np.ndarray, noise_values: np.ndarray, \n",
    "                      slice_locations: np.ndarray = None):\n",
    "    \"\"\"\n",
    "    Plot noise profile overlaid on coronal reconstruction.\n",
    "    Similar to visualization in Christianson et al. Fig 3.\n",
    "    \"\"\"\n",
    "    # Get central coronal slice\n",
    "    mid_idx = ct_data.shape[1] // 2\n",
    "    coronal_slice = ct_data[:, mid_idx, :]\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot coronal image\n",
    "    im = ax1.imshow(coronal_slice.T, cmap='gray', aspect='auto')\n",
    "    ax1.set_xlabel('Slice Number')\n",
    "    ax1.set_ylabel('Position (pixels)')\n",
    "    \n",
    "    # Create second y-axis for noise values\n",
    "    ax2 = ax1.twinx()\n",
    "    if slice_locations is not None:\n",
    "        ax2.plot(noise_values, slice_locations, 'r-', linewidth=2)\n",
    "        ax2.set_ylabel('Slice Location (mm)', color='r')\n",
    "    else:\n",
    "        ax2.plot(noise_values, 'r-', linewidth=2)\n",
    "        ax2.set_ylabel('Noise (HU)', color='r')\n",
    "    \n",
    "    plt.title('Noise Profile vs. Anatomical Position')\n",
    "    plt.tight_layout()\n",
    "    return fig, (ax1, ax2)\n",
    "\n",
    "def compute_regional_noise(ct_data: np.ndarray, noise_values: np.ndarray, \n",
    "                         method: str = 'landmarks', \n",
    "                         organ_masks: dict = None):\n",
    "    \"\"\"\n",
    "    Compute regional noise values using either anatomical landmarks or organ masks.\n",
    "    \n",
    "    As described in Özsoykal et al. \"Size-specific dose estimates in chest, abdomen,\n",
    "    and pelvis CT examinations of pediatric patients\":\n",
    "    \"Anatomic markers used to separate each region were determined as top and bottom \n",
    "    of the lungs, top of the liver and pelvic crest, top of the pelvic crest and \n",
    "    pubic symphysis, respectively, for chest, abdomen, and pelvis\"\n",
    "    \n",
    "    Args:\n",
    "        ct_data: CT volume\n",
    "        noise_values: Per-slice noise measurements\n",
    "        method: Either 'landmarks' or 'masks'\n",
    "        organ_masks: Dict of organ masks if using mask method\n",
    "    \"\"\"\n",
    "    if method == 'landmarks':\n",
    "        # Find anatomical landmarks\n",
    "        # This would need manual input or automated detection\n",
    "        regions = {\n",
    "            'chest': slice(None, None),  # Replace with actual slice ranges\n",
    "            'abdomen': slice(None, None),\n",
    "            'pelvis': slice(None, None)\n",
    "        }\n",
    "        \n",
    "    elif method == 'masks':\n",
    "        if organ_masks is None:\n",
    "            raise ValueError(\"Organ masks required for mask-based method\")\n",
    "        regions = {}\n",
    "        for organ, mask in organ_masks.items():\n",
    "            # Find slices where organ is present\n",
    "            organ_slices = np.any(mask, axis=(1,2))\n",
    "            regions[organ] = slice(np.where(organ_slices)[0][0],\n",
    "                                 np.where(organ_slices)[0][-1])\n",
    "    \n",
    "    # Compute regional statistics\n",
    "    regional_stats = {}\n",
    "    for region, slices in regions.items():\n",
    "        region_noise = noise_values[slices]\n",
    "        regional_stats[region] = {\n",
    "            'mean': np.nanmean(region_noise),\n",
    "            'std': np.nanstd(region_noise),\n",
    "            'median': np.nanmedian(region_noise),\n",
    "            'n_slices': np.sum(~np.isnan(region_noise))\n",
    "        }\n",
    "    \n",
    "    return regional_stats\n",
    "   \n",
    "def compute_tian_noise(ct_data: np.ndarray, body_mask: np.ndarray = None, \n",
    "                      roi_size: int = 30) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute noise using Tian's subtraction method.\n",
    "    Implementation follows: Tian X, Samei E. Accurate assessment and prediction of \n",
    "    noise in clinical CT images. Med Phys. 2016;43(1):475-482.\n",
    "    \n",
    "    Steps:\n",
    "    1. Subtract sequential slices to remove anatomical structures\n",
    "    2. Calculate gradient threshold as 2 × mean gradient magnitude\n",
    "    3. Identify regions without strong edges\n",
    "    4. Measure noise in homogeneous regions using non-overlapping ROIs\n",
    "    5. Scale by 1/√2 to account for subtraction\n",
    "    \n",
    "    Args:\n",
    "        ct_data: 3D CT volume in HU [slices, rows, cols]\n",
    "        body_mask: Binary mask of body region (1 inside, 0 outside)\n",
    "        roi_size: Size of ROI patches for noise analysis\n",
    "        \n",
    "    Returns:\n",
    "        noise_values: Array of noise measurements per slice\n",
    "    \"\"\"\n",
    "    num_slices = ct_data.shape[0]\n",
    "    noise_values = np.zeros(num_slices)\n",
    "    \n",
    "    for i in range(num_slices - 1):\n",
    "        try:\n",
    "            # 1. Sequential slice subtraction\n",
    "            diff_image = ct_data[i] - ct_data[i + 1]\n",
    "            \n",
    "            # Apply body mask if provided\n",
    "            if body_mask is not None:\n",
    "                combined_mask = body_mask[i] & body_mask[i + 1]\n",
    "                diff_image = np.where(combined_mask, diff_image, np.nan)\n",
    "            \n",
    "            # 2. Calculate gradient threshold\n",
    "            dx = cv2.Sobel(diff_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "            dy = cv2.Sobel(diff_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "            gradient_mag = np.sqrt(dx**2 + dy**2)\n",
    "            grad_threshold = 2 * np.nanmean(gradient_mag)\n",
    "            \n",
    "            # 3. Create edge mask\n",
    "            edge_mask = gradient_mag > grad_threshold\n",
    "            \n",
    "            # 4. ROI-based noise analysis\n",
    "            valid_noise_values = []\n",
    "            \n",
    "            # Use non-overlapping ROIs\n",
    "            for y in range(0, diff_image.shape[0] - roi_size + 1, roi_size):\n",
    "                for x in range(0, diff_image.shape[1] - roi_size + 1, roi_size):\n",
    "                    roi = diff_image[y:y + roi_size, x:x + roi_size]\n",
    "                    roi_edge_mask = edge_mask[y:y + roi_size, x:x + roi_size]\n",
    "                    imtool3d(roi)\n",
    "                    # Skip if ROI contains edges or NaN values\n",
    "                    if np.any(roi_edge_mask) or np.any(np.isnan(roi)):\n",
    "                        continue\n",
    "                    \n",
    "                    # 5. Calculate noise (SD/√2 due to subtraction)\n",
    "                    noise = np.std(roi) / np.sqrt(2)\n",
    "                    valid_noise_values.append(noise)\n",
    "            \n",
    "            if valid_noise_values:\n",
    "                    # Calculate mode of noise values using histogram\n",
    "                # Use appropriate bin size for continuous data\n",
    "                hist, bins = np.histogram(valid_noise_values, bins=50)  # Adjust bin number as needed\n",
    "                mode_idx = np.argmax(hist)\n",
    "                noise_values[i] = bins[mode_idx]  # Use bin center where count is highest\n",
    "            else:\n",
    "                noise_values[i] = np.nan\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing slice {i}: {str(e)}\")\n",
    "            noise_values[i] = np.nan\n",
    "    \n",
    "    # Handle last slice\n",
    "    noise_values[-1] = noise_values[-2] if not np.isnan(noise_values[-2]) else np.nan\n",
    "    \n",
    "    return noise_values\n",
    "\n",
    "def validate_tian_noise(ct_data: np.ndarray, noise_values: np.ndarray, \n",
    "                       slice_idx: int = None) -> None:\n",
    "    \"\"\"\n",
    "    Validate Tian noise measurements.\n",
    "    \n",
    "    Args:\n",
    "        ct_data: Original CT volume\n",
    "        noise_values: Computed noise values\n",
    "        slice_idx: Optional slice index for visualization\n",
    "    \"\"\"\n",
    "    if slice_idx is None:\n",
    "        slice_idx = ct_data.shape[0] // 2\n",
    "        \n",
    "    # Create validation visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    \n",
    "    # Original slices\n",
    "    axes[0,0].imshow(ct_data[slice_idx], cmap='gray')\n",
    "    axes[0,0].set_title('Original Slice')\n",
    "    \n",
    "    # Difference image\n",
    "    diff_image = ct_data[slice_idx] - ct_data[slice_idx + 1]\n",
    "    im2 = axes[0,1].imshow(diff_image, cmap='gray')\n",
    "    axes[0,1].set_title('Difference Image')\n",
    "    plt.colorbar(im2, ax=axes[0,1])\n",
    "    \n",
    "    # Edge detection\n",
    "    dx = cv2.Sobel(diff_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    dy = cv2.Sobel(diff_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_mag = np.sqrt(dx**2 + dy**2)\n",
    "    grad_threshold = 2 * np.nanmean(gradient_mag)\n",
    "    edge_mask = gradient_mag > grad_threshold\n",
    "    \n",
    "    axes[1,0].imshow(edge_mask, cmap='gray')\n",
    "    axes[1,0].set_title('Edge Detection')\n",
    "    \n",
    "    # Noise values plot\n",
    "    valid_slices = ~np.isnan(noise_values)\n",
    "    axes[1,1].plot(range(len(noise_values))[valid_slices], \n",
    "                  noise_values[valid_slices], 'b-')\n",
    "    axes[1,1].set_xlabel('Slice Number')\n",
    "    axes[1,1].set_ylabel('Noise (HU)')\n",
    "    axes[1,1].set_title('Noise Values')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nNoise Statistics:\")\n",
    "    print(f\"Mean noise: {np.nanmean(noise_values):.2f} HU\")\n",
    "    print(f\"Std deviation: {np.nanstd(noise_values):.2f} HU\")\n",
    "    print(f\"Range: {np.nanmin(noise_values):.2f} - {np.nanmax(noise_values):.2f} HU\")\n",
    "# Modify process_case function\n",
    "def process_case(case_root: str, case_number: int = None):\n",
    "    \"\"\"\n",
    "    Processes a single patient case with configurable metrics computation.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Processing case in: {case_root}\")\n",
    "    \n",
    "    primary_folder = os.path.basename(os.path.dirname(case_root))  \n",
    "    second_folder = os.path.basename(case_root)\n",
    "\n",
    "    ct_data, pixel_spacing, tube_current, slice_locations = read_ct_volume(case_root)\n",
    "    \n",
    "    # Only get RTSTRUCT if needed for GNI or WED\n",
    "    mask = None\n",
    "    if COMPUTE_CONFIG['GNI'] or COMPUTE_CONFIG['WED']:\n",
    "        _, rtstruct_file = get_dicom_files(os.path.dirname(case_root))\n",
    "        if not rtstruct_file:\n",
    "            logging.warning(f\"Skipping case {case_root} due to missing RTSTRUCT.\")\n",
    "            return None\n",
    "            \n",
    "        rtstruct = RTStructBuilder.create_from(dicom_series_path=case_root, rt_struct_path=rtstruct_file)\n",
    "        contour = rtstruct.get_roi_mask_by_name(\"Skin\").astype(np.float32).transpose(2,0,1).copy()\n",
    "        contour = np.flip(contour, axis=0)\n",
    "        mask = create_body_mask(contour)\n",
    "\n",
    "    # Initialize results\n",
    "    results = {}\n",
    "    slice_indices = list(range(len(slice_locations)))\n",
    "    \n",
    "    # Compute only requested metrics\n",
    "    if COMPUTE_CONFIG['WED']:\n",
    "        pixel_width, pixel_height = pixel_spacing[0], pixel_spacing[1]\n",
    "        wed = compute_wed(ct_data, mask, pixel_width, pixel_height)\n",
    "        results['WED'] = wed\n",
    "        \n",
    "    if COMPUTE_CONFIG['GNI']:\n",
    "        gni = compute_gni_optimized(ct_data, kernel_size_mm=6, hu_bins=0.1, \n",
    "                                  pixel_spacing=pixel_spacing, body_mask=mask)\n",
    "        results['GNI'] = gni\n",
    "        \n",
    "    if COMPUTE_CONFIG['TIAN']:\n",
    "        tian_noise = compute_tian_noise(ct_data, body_mask=mask)\n",
    "        results['Tian_Noise'] = tian_noise\n",
    "        \n",
    "        # Optional validation\n",
    "        if COMPUTE_CONFIG['VALIDATE_SUBSET'] and case_number is not None:\n",
    "            if case_number % COMPUTE_CONFIG['VALIDATION_INTERVAL'] == 0:\n",
    "                logging.info(f\"Validating case {case_number}\")\n",
    "                validate_tian_noise(ct_data, tian_noise)\n",
    "\n",
    "    # Save to Excel - only save computed metrics\n",
    "    output_filename = f\"{primary_folder}_{second_folder}_metrics.xlsx\"\n",
    "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "        for metric_name, metric_values in results.items():\n",
    "            pd.DataFrame([metric_values], \n",
    "                        index=[f\"{primary_folder}/{second_folder}\"], \n",
    "                        columns=slice_indices).to_excel(writer, sheet_name=metric_name)\n",
    "        \n",
    "        # Always save tube current as it's available from DICOM\n",
    "        pd.DataFrame([tube_current], \n",
    "                    index=[f\"{primary_folder}/{second_folder}\"], \n",
    "                    columns=slice_indices).to_excel(writer, sheet_name=\"Tube Current\")\n",
    "\n",
    "    logging.info(f\"Results saved to {output_filename}\")\n",
    "    return output_filename\n",
    "\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# from typing import List, Dict\n",
    "# from openpyxl import Workbook\n",
    "\n",
    "# def process_case(case_root: str):\n",
    "#     \"\"\"\n",
    "#     Processes a single patient case and saves GNI, WED, and Tube Current per slice into an Excel file.\n",
    "#     \"\"\"\n",
    "#     logging.info(f\"Processing case in: {case_root}\")\n",
    "    \n",
    "#     # Extract folder names for the output file\n",
    "#     primary_folder = os.path.basename(os.path.dirname(case_root))  # e.g., Pediatric-CT-SEG-0B387FB5\n",
    "#     second_folder = os.path.basename(case_root)  # e.g., 09-02-2004-NA-CT-86719\n",
    "\n",
    "#     # Read CT volume\n",
    "#     ct_data, pixel_spacing, tube_current, slice_locations = read_ct_volume(case_root)\n",
    "    \n",
    "#     # Get RTSTRUCT file\n",
    "#     _, rtstruct_file = get_dicom_files(os.path.dirname(case_root))\n",
    "\n",
    "#     # Parse RTSTRUCT to obtain skin ROI\n",
    "#     rtstruct = RTStructBuilder.create_from(dicom_series_path=case_root, rt_struct_path=rtstruct_file)\n",
    "#     contour = rtstruct.get_roi_mask_by_name(\"Skin\").astype(np.float32).transpose(2,0,1).copy()\n",
    "#     contour = np.flip(contour, axis=0)\n",
    "#     mask = create_body_mask(contour)\n",
    "\n",
    "#     # Compute WED\n",
    "#     pixel_width, pixel_height = pixel_spacing[0], pixel_spacing[1]\n",
    "#     wed = compute_wed(ct_data, mask, pixel_width, pixel_height)\n",
    "\n",
    "#     # Compute GNI\n",
    "#     gni = compute_gni_optimized(ct_data, kernel_size_mm=6, hu_bins=0.1, pixel_spacing=pixel_spacing)\n",
    "\n",
    "#     # Store results in dictionary format for Excel output\n",
    "#     slice_indices = list(range(len(slice_locations)))  # Slice indices\n",
    "#     gni_values = gni  # Per slice GNI\n",
    "#     wed_values = wed  # Per slice WED\n",
    "#     tube_current_values = tube_current  # Per slice tube current\n",
    "\n",
    "#     # Convert results to DataFrame format for Excel output\n",
    "#     gni_df = pd.DataFrame([gni_values], index=[f\"{primary_folder}/{second_folder}\"], columns=slice_indices)\n",
    "#     wed_df = pd.DataFrame([wed_values], index=[f\"{primary_folder}/{second_folder}\"], columns=slice_indices)\n",
    "#     tube_current_df = pd.DataFrame([tube_current_values], index=[f\"{primary_folder}/{second_folder}\"], columns=slice_indices)\n",
    "\n",
    "#     # Create Excel Writer with multiple sheets\n",
    "#     output_filename = f\"{primary_folder}_{second_folder}_metrics.xlsx\"\n",
    "#     with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "#         gni_df.to_excel(writer, sheet_name=\"GNI\")\n",
    "#         wed_df.to_excel(writer, sheet_name=\"WED\")\n",
    "#         tube_current_df.to_excel(writer, sheet_name=\"Tube Current\")\n",
    "\n",
    "#     logging.info(f\"Results saved to {output_filename}\")\n",
    "\n",
    "#     return output_filename\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Main Function\n",
    "# =============================================================================\n",
    "\n",
    "# Modify main function to include case numbering\n",
    "def main():\n",
    "    master_dir = \"/media/nvme/Python/PediatricCTDataset/manifest-1647979711903/Pediatric-CT-SEG/\"\n",
    "    \n",
    "    # Initialize result storage based on config\n",
    "    all_results = {\n",
    "        'Tube Current': []  # Always include tube current\n",
    "    }\n",
    "    # Add enabled metrics\n",
    "    if COMPUTE_CONFIG['GNI']:\n",
    "        all_results['GNI'] = []\n",
    "    if COMPUTE_CONFIG['TIAN']:\n",
    "        all_results['Tian_Noise'] = []\n",
    "    if COMPUTE_CONFIG['WED']:\n",
    "        all_results['WED'] = []\n",
    "    \n",
    "    dicom_dirs = set()\n",
    "    for root, _, files in os.walk(master_dir):\n",
    "        if any(f.lower().endswith('.dcm') for f in files):\n",
    "            if \"CT\" in os.path.basename(root) and \"RTSTRUCT\" not in os.path.basename(root):\n",
    "                dicom_dirs.add(root)\n",
    "\n",
    "    dicom_dirs = sorted(list(dicom_dirs))\n",
    "\n",
    "    for case_num, case_root in enumerate(dicom_dirs, 1):\n",
    "        print(f\"Processing: {case_root}\")\n",
    "        try:\n",
    "            # Get folder names for index\n",
    "            primary_folder = os.path.basename(os.path.dirname(case_root))\n",
    "            second_folder = os.path.basename(case_root)\n",
    "            index_name = f\"{primary_folder}/{second_folder}\"\n",
    "            \n",
    "            # Process the case\n",
    "            ct_data, pixel_spacing, tube_current, slice_locations = read_ct_volume(case_root)\n",
    "            \n",
    "            # Only get RTSTRUCT if needed for GNI or WED\n",
    "            mask = None\n",
    "            if COMPUTE_CONFIG['GNI'] or COMPUTE_CONFIG['WED']:\n",
    "                _, rtstruct_file = get_dicom_files(os.path.dirname(case_root))\n",
    "                if not rtstruct_file:\n",
    "                    logging.warning(f\"Skipping case {case_root} due to missing RTSTRUCT.\")\n",
    "                    continue\n",
    "\n",
    "                rtstruct = RTStructBuilder.create_from(dicom_series_path=case_root, rt_struct_path=rtstruct_file)\n",
    "                contour = rtstruct.get_roi_mask_by_name(\"Skin\").astype(np.float32).transpose(2,0,1).copy()\n",
    "                contour = np.flip(contour, axis=0)\n",
    "                mask = create_body_mask(contour)\n",
    "            \n",
    "            # Create series for each enabled metric\n",
    "            slice_indices = list(range(len(slice_locations)))\n",
    "            \n",
    "            # Compute metrics based on configuration\n",
    "            if COMPUTE_CONFIG['WED']:\n",
    "                wed = compute_wed(ct_data, mask, pixel_spacing[0], pixel_spacing[1])\n",
    "                wed_series = pd.DataFrame([wed], index=[index_name], columns=slice_indices)\n",
    "                all_results['WED'].append(wed_series)\n",
    "            \n",
    "            if COMPUTE_CONFIG['GNI']:\n",
    "                gni = compute_gni_optimized(ct_data, kernel_size_mm=6, hu_bins=0.1, \n",
    "                                          pixel_spacing=pixel_spacing, body_mask=mask)\n",
    "                gni_series = pd.DataFrame([gni], index=[index_name], columns=slice_indices)\n",
    "                all_results['GNI'].append(gni_series)\n",
    "            \n",
    "            if COMPUTE_CONFIG['TIAN']:\n",
    "                tian_noise = compute_tian_noise(ct_data, body_mask=mask)\n",
    "                tian_series = pd.DataFrame([tian_noise], index=[index_name], columns=slice_indices)\n",
    "                all_results['Tian_Noise'].append(tian_series)\n",
    "                \n",
    "                # Optional validation\n",
    "                if COMPUTE_CONFIG['VALIDATE_SUBSET'] and case_num % COMPUTE_CONFIG['VALIDATION_INTERVAL'] == 0:\n",
    "                    validate_tian_noise(ct_data, tian_noise)\n",
    "            \n",
    "            # Always store tube current\n",
    "            tube_current_series = pd.DataFrame([tube_current], index=[index_name], columns=slice_indices)\n",
    "            all_results['Tube Current'].append(tube_current_series)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error processing case {case_root}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save final results\n",
    "    output_filename = 'all_metrics.xlsx'\n",
    "    with pd.ExcelWriter(output_filename) as writer:\n",
    "        for metric_name, results_list in all_results.items():\n",
    "            if results_list:  # Only save if we have results\n",
    "                combined_metric = pd.concat(results_list)\n",
    "                combined_metric.to_excel(writer, sheet_name=metric_name)\n",
    "    \n",
    "    print(f\"All results saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
